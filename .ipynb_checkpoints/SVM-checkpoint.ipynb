{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import read_mimic_flat\n",
    "import os\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pickle\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Flatten, Convolution1D, AtrousConvolution1D\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalMaxPooling1D, Lambda, concatenate\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dropout, Reshape, Activation\n",
    "from keras.layers.pooling import AveragePooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adagrad\n",
    "from collections import defaultdict\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.objectives import binary_crossentropy, categorical_crossentropy\n",
    "#tf.python.control_flow_ops = tf\n",
    "from full_eval import full_evaluate\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expand = False\n",
    "shaped = True\n",
    "add_desc = False\n",
    "generlize = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_dict = {}\n",
    "for line in open('mimic/2/ICD9_descriptions'):\n",
    "    line = line.strip().split('\\t')\n",
    "    desc_dict[line[0]] = line[1]\n",
    "    \n",
    "def get_data():\n",
    "    global VOCAB_SIZE, NUM_OF_CLASSES, SEQ_LEN, reader\n",
    "    def to_categorical(y, nb_classes=None):\n",
    "        y = np.array(y)\n",
    "        if not nb_classes:\n",
    "            nb_classes = np.max(y) + 1\n",
    "        n = y.shape[0]\n",
    "        categorical = np.zeros((n, nb_classes))\n",
    "        for i, sample in enumerate(y):\n",
    "            for l in sample:\n",
    "                categorical[i, l] = 1\n",
    "        return categorical\n",
    "\n",
    "    reader = read_mimic_flat.mimic_reader(version, expand=expand, shaped=shaped, add_desc=add_desc, generlize=generlize)\n",
    "    X_train, X_test, y_trains, y_test, tokens_vocab, labels_vocab = reader.read_mimic()\n",
    "\n",
    "    VOCAB_SIZE = len(tokens_vocab) + 1\n",
    "    NUM_OF_CLASSES = len(labels_vocab)\n",
    "\n",
    "\n",
    "    X_train = pad_sequences(X_train, maxlen=None, dtype='int32',\n",
    "        padding='pre', truncating='pre', value=len(tokens_vocab))\n",
    "    X_test = pad_sequences(X_test, maxlen=len(X_train[0]), dtype='int32',\n",
    "        padding='pre', truncating='pre', value=len(tokens_vocab))\n",
    "\n",
    "    SEQ_LEN = len(X_train[0])\n",
    "\n",
    "    y_train = to_categorical(y_trains, NUM_OF_CLASSES)\n",
    "    y_test = to_categorical(y_test, NUM_OF_CLASSES)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, tokens_vocab, labels_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '2'\n",
    "generlize = True\n",
    "\n",
    "X_train, X_test, y_train, y_test, tokens_vocab, labels_vocab = get_data()\n",
    "\n",
    "\n",
    "\n",
    "#print(full_evaluate(model1.predict(X_test, batch_size=batch_size), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20533/20533 [04:22<00:00, 76.21it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = [' '.join([tokens_vocab[w] for w in sent if w < len(tokens_vocab)]) for sent in tqdm(X_train)]\n",
    "X_test = [' '.join([tokens_vocab[w] for w in sent if w < len(tokens_vocab)]) for sent in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_features=10000, stop_words='english')\n",
    "X_train_v = vectorizer.fit_transform(X_train)\n",
    "X_test_v = vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 41 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 139 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 169 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 239 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 326 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 404 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 644 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 669 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 679 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 827 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(), n_jobs=1)\n",
    "\n",
    "clf.fit(X_train_v, y_train)\n",
    "pred = clf.predict(X_test_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 micro:(0.24219292158223457, 0.02901442407615247, 0.05182078028137644)\n",
      "f1 macro: (0.0090689217265576983, 0.0013965274162279252, 0.0021531491216464187)\n",
      "auc_pr micro: 0.14100251055\n",
      "auc_pr macro: 0.467951346569\n",
      "auc_roc micro: 0.513996759685\n",
      "auc_roc macro: 0.500036007665\n",
      "precision_at_k 8: 0.0437664329535\n",
      "precision_at_k 40: 0.0141323400526\n",
      "recall_at_k 8: 0.0332127862992\n",
      "recall_at_k 40: 0.0536226462152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(full_evaluate(pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
